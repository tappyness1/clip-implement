{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from src.dataset import UnsplashDataset, FlickrDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = UnsplashDataset(\"../../data/unsplash/photos.tsv*\")\n",
    "dataset = FlickrDataset(image_folder_path = \"../../data/flickr-dataset/Images/\", caption_path = \"../../data/flickr-dataset/captions.txt\")\n",
    "train_loader = DataLoader(dataset, batch_size = 5, shuffle=True)    \n",
    "img, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, model_name=\"distilbert-base-uncased\", pretrained=True, trainable=True):\n",
    "        super().__init__()\n",
    "        if pretrained:\n",
    "            self.model = DistilBertModel.from_pretrained(model_name)\n",
    "            \n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = trainable\n",
    "\n",
    "        # we are using the CLS token hidden representation as the sentence's embedding\n",
    "        self.target_token_idx = 0\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = output.last_hidden_state\n",
    "        return last_hidden_state[:, self.target_token_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = TextEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tokenizer(label, padding=True, truncation=True, max_length = 76, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1037,  2879,  5629,  1010,  6729,  2058,  1037,  9540,  3561,\n",
       "          2007,  2048,  2312, 25730,  2015,  1012,   102],\n",
       "        [  101,  2048,  2273,  1999, 17072,  4133,  2012,  1037,  2795,  5948,\n",
       "          5404,  1012,   102,     0,     0,     0,     0],\n",
       "        [  101,  2048,  2308,  5102,  2007, 11228,  6961,  2058,  2037,  4641,\n",
       "          2298, 14136,  2012,  1996,  8088,  1012,   102],\n",
       "        [  101,  2274,  3057,  2006,  1037, 11485,  4536,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1037,  3598,  2447,  4324,  2010,  7151,  1998,  4152,  3201,\n",
       "          2005,  1996,  2208,  1012,   102,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0835, -0.1285, -0.2291,  ..., -0.0572,  0.3771, -0.0428],\n",
       "        [ 0.2269,  0.0358, -0.0390,  ..., -0.1364,  0.4991, -0.0495],\n",
       "        [ 0.2484, -0.0023, -0.0976,  ..., -0.1935,  0.4512,  0.1045],\n",
       "        [-0.2170, -0.5539, -0.1784,  ..., -0.1827,  0.4049,  0.0035],\n",
       "        [-0.3889, -0.2942, -0.0121,  ..., -0.0645,  0.2578,  0.2159]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model(data['input_ids'], data['attention_mask'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
